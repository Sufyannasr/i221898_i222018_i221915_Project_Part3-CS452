{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13838894,"sourceType":"datasetVersion","datasetId":8813940}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Learning Project Part 3","metadata":{}},{"cell_type":"markdown","source":"## By: i221898 i222018 i221915","metadata":{}},{"cell_type":"markdown","source":"## Implementation of improved version","metadata":{}},{"cell_type":"code","source":"import os, sys, math, random, time, glob\nfrom typing import Tuple, Optional\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision\nfrom torchvision import transforms as T\nimport timm\n\n# -------------------------\n# Configuration\n# -------------------------\nSEED = 42\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# Dataset / file paths (Kermany pediatric pneumonia dataset)\nDATA_ROOT = \"/kaggle/input/xraydata/chest_xray\"\nIMG_SIZE = 224\nBATCH_SIZE = 16\nEPOCHS = 20\nLR = 5e-5             # slightly larger LR for head-training (we'll reduce when unfreezing)\nWEIGHT_DECAY = 1e-4\n\n# Loss weights (reduced segmentation influence)\nLAMBDA_SEG = 0.0      # disable seg auxiliary initially; enable small value later if desired\nLAMBDA_ATT = 0.0\nSAVE_DIR = \"./ckpt_hybrid_deit_fixed\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n\n# Early stopping\nPATIENCE = 5\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\n# -------------------------\n# Verify dataset\n# -------------------------\ndef verify_dataset(root):\n    ok = os.path.isdir(os.path.join(root, \"train\")) and os.path.isdir(os.path.join(root, \"test\"))\n    return ok\n\nif not verify_dataset(DATA_ROOT):\n    print(\"Dataset not found locally at\", DATA_ROOT)\n    print(\"If running on Kaggle: add the 'Chest X-ray Images (Pneumonia)' dataset via the Notebook 'Add data' UI and re-run.\")\nelse:\n    print(\"Dataset found:\", DATA_ROOT)\n\n# -------------------------\n# Utility: unsupervised lung mask generator (heuristic)\n# -------------------------\ndef generate_lung_mask_orig(image_bgr: np.ndarray) -> np.ndarray:\n    if image_bgr.ndim == 3:\n        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n    else:\n        gray = image_bgr.copy()\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    cl = clahe.apply(gray)\n    blur = cv2.GaussianBlur(cl, (5,5), 0)\n    _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    th_inv = 255 - th\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n    closed = cv2.morphologyEx(th_inv, cv2.MORPH_CLOSE, kernel, iterations=2)\n    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(opened, connectivity=8)\n    if num_labels <= 1:\n        mask = (opened > 0).astype(np.uint8)\n    else:\n        areas = stats[1:, cv2.CC_STAT_AREA]\n        idx_sorted = np.argsort(areas)[::-1]\n        mask = np.zeros_like(opened, dtype=np.uint8)\n        for i in idx_sorted[:2]:\n            lbl = i+1\n            mask[labels == lbl] = 1\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15)))\n    return mask.astype(np.uint8)\n\n# -------------------------\n# Dataset class for Kermany dataset (train/val/test)\n# -------------------------\nclass PediatricCXRDataset(Dataset):\n    def __init__(self, root_dir, split=\"train\", transform=None, mask_transform=None, generate_mask=True):\n        self.root = root_dir\n        self.split = split\n        self.transform = transform\n        self.mask_transform = mask_transform\n        self.generate_mask = generate_mask\n        self.samples = []\n        split_dir = os.path.join(root_dir, split)\n        if not os.path.isdir(split_dir):\n            raise RuntimeError(f\"Split dir not found: {split_dir}\")\n        for label_name in [\"PNEUMONIA\", \"NORMAL\"]:\n            lab_dir = os.path.join(split_dir, label_name)\n            if not os.path.isdir(lab_dir):\n                continue\n            for p in glob.glob(os.path.join(lab_dir, \"*\")):\n                if p.lower().endswith((\".jpeg\",\".jpg\",\".png\")):\n                    label = 1 if label_name == \"PNEUMONIA\" else 0\n                    self.samples.append((p, label))\n        if len(self.samples) == 0:\n            raise RuntimeError(f\"No samples found under {split_dir}\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        img_bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n        if img_bgr is None:\n            img_bgr = np.zeros((IMG_SIZE,IMG_SIZE,3), dtype=np.uint8)\n        h,w = img_bgr.shape[:2]\n        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n        mask = generate_lung_mask_orig(img_bgr) if self.generate_mask else np.zeros((h,w),dtype=np.uint8)\n        img_resized = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)\n        mask_resized = cv2.resize(mask, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n        if self.transform is not None:\n            from PIL import Image\n            pil = Image.fromarray(img_resized)\n            img_t = self.transform(pil)\n        else:\n            img_t = T.ToTensor()(img_resized)\n        if self.mask_transform is not None:\n            from PIL import Image\n            pil_mask = Image.fromarray((mask_resized*255).astype(np.uint8))\n            mask_t = self.mask_transform(pil_mask)\n        else:\n            mask_t = torch.from_numpy(mask_resized).unsqueeze(0).float()/255.0\n        return img_t, torch.tensor(label, dtype=torch.long), mask_t\n\n# -------------------------\n# Prepare datasets & transforms\n# -------------------------\nprint(\"Preparing datasets...\")\n\noriginal_train_ds = PediatricCXRDataset(DATA_ROOT, split=\"train\", transform=None, mask_transform=None, generate_mask=True)\ntest_ds = PediatricCXRDataset(DATA_ROOT, split=\"test\", transform=None, mask_transform=None, generate_mask=True)\n\n# Stratified split indices\ntrain_samples = original_train_ds.samples\ntrain_labels_for_split = [label for _, label in train_samples]\ntrain_idx, val_idx = train_test_split(\n    range(len(train_samples)),\n    test_size=0.15,\n    stratify=train_labels_for_split,\n    random_state=SEED\n)\n\nprint(f\"Original train size: {len(original_train_ds)}\")\nprint(f\"Train indices: {len(train_idx)}, Val indices: {len(val_idx)}\")\n\n# Transforms\ntrain_tf = T.Compose([\n    T.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.RandomApply([T.ColorJitter(brightness=0.12, contrast=0.12)], p=0.5),\n    T.RandomRotation(10),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\ntest_tf = T.Compose([\n    T.Resize((IMG_SIZE, IMG_SIZE)),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\nmask_tf = T.Compose([T.ToTensor()])\n\nclass TransformedSubset(Dataset):\n    def __init__(self, dataset, indices, transform=None, mask_transform=None):\n        self.dataset = dataset\n        self.indices = indices\n        self.transform = transform\n        self.mask_transform = mask_transform\n        \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        actual_idx = self.indices[idx]\n        img, label, mask = self.dataset[actual_idx]\n        \n        if self.transform:\n            from PIL import Image\n            img_pil = T.ToPILImage()(img)\n            img = self.transform(img_pil)\n        \n        if self.mask_transform:\n            from PIL import Image\n            mask_pil = T.ToPILImage()(mask)\n            mask = self.mask_transform(mask_pil)\n            \n        return img, label, mask\n\n# Create train/val/test subsets\ntrain_ds = TransformedSubset(original_train_ds, train_idx, transform=train_tf, mask_transform=mask_tf)\nval_ds = TransformedSubset(original_train_ds, val_idx, transform=test_tf, mask_transform=mask_tf)\ntest_ds = PediatricCXRDataset(DATA_ROOT, split=\"test\", transform=test_tf, mask_transform=mask_tf, generate_mask=True)\n\n# -------------------------\n# Weighted sampler to handle imbalance\n# -------------------------\ntrain_label_list = [original_train_ds.samples[i][1] for i in train_idx]\nclass_counts = np.bincount(train_label_list)\ninv_freq = {i: 1.0 / class_counts[i] for i in range(len(class_counts))}\nsample_weights = [inv_freq[l] for l in train_label_list]\nsampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True, drop_last=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\nprint(\"Sizes: train\", len(train_ds), \"val\", len(val_ds), \"test\", len(test_ds))\n\n# -------------------------\n# Calculate class weights (for loss)\n# -------------------------\ntrain_labels = [original_train_ds.samples[i][1] for i in train_idx]\nclass_counts = np.bincount(train_labels)\nclass_weights = 1. / class_counts\nclass_weights = class_weights / class_weights.sum() * len(class_counts)\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\nprint(f\"Class counts: {class_counts}, Class weights: {class_weights.cpu().numpy()}\")\n\n# -------------------------\n# Model components with DEiT Stem\n# -------------------------\nclass DEiTStem(nn.Module):\n    def __init__(self, out_channels=128):\n        super().__init__()\n        self.deit = timm.create_model('deit_base_patch16_224', pretrained=True, num_classes=0)\n        self.projection = nn.Conv2d(768, out_channels, 1)\n        \n    def forward(self, x):\n        x = self.deit.forward_features(x)\n        patch_tokens = x[:, 1:]\n        batch_size = x.shape[0]\n        features = patch_tokens.reshape(batch_size, 14, 14, 768).permute(0, 3, 1, 2)\n        features = self.projection(features)\n        features = F.interpolate(features, size=(56, 56), mode='bilinear', align_corners=False)\n        return features\n\nclass SegHead(nn.Module):\n    def __init__(self, in_ch, mid_ch=64):\n        super().__init__()\n        self.decoder = nn.Sequential(\n            nn.Dropout2d(0.1),\n            nn.Conv2d(in_ch, mid_ch, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(mid_ch, mid_ch//2, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(mid_ch//2, 1, 1)\n        )\n\n    def forward(self, f):\n        return self.decoder(f)\n\nclass SimpleTransformerEncoder(nn.Module):\n    def __init__(self, d_model=128, nhead=8, num_layers=3, dim_feedforward=256, dropout=0.1):\n        super().__init__()\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, \n            dropout=dropout, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.norm = nn.LayerNorm(d_model)\n\n    def forward(self, tokens, src_key_padding_mask=None):\n        out = self.encoder(tokens, src_key_padding_mask=src_key_padding_mask)\n        out = self.norm(out)\n        return out\n\nclass CrossAttentionFusion(nn.Module):\n    def __init__(self, d_model=128, nhead=8):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, d_model), \n            nn.ReLU(), \n            nn.Dropout(0.1),\n            nn.LayerNorm(d_model)\n        )\n\n    def forward(self, cls_tok, kv_tokens):\n        out, attn_w = self.attn(query=cls_tok, key=kv_tokens, value=kv_tokens, need_weights=True)\n        out = self.ffn(out.squeeze(1)).unsqueeze(1)\n        return out, attn_w\n\nclass HybridLungViT(nn.Module):\n    def __init__(self, num_classes=2, d_model=128, token_grid=(7,7)):\n        super().__init__()\n        self.stem = DEiTStem(out_channels=d_model)\n        self.seghead = SegHead(in_ch=d_model, mid_ch=64)\n        self.token_grid = token_grid\n        self.d_model = d_model\n        self.left_enc = SimpleTransformerEncoder(d_model=d_model, nhead=8, num_layers=2, dropout=0.1)\n        self.right_enc = SimpleTransformerEncoder(d_model=d_model, nhead=8, num_layers=2, dropout=0.1)\n        self.global_enc = SimpleTransformerEncoder(d_model=d_model, nhead=8, num_layers=2, dropout=0.1)\n        self.fusion = CrossAttentionFusion(d_model=d_model, nhead=8)\n        self.cls_head = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.LayerNorm(d_model), \n            nn.Linear(d_model, num_classes)\n        )\n        self.cls_token = nn.Parameter(torch.randn(1,1,d_model))\n\n    def forward(self, x, mask=None):\n        B = x.size(0)\n        f = self.stem(x)\n        seg_logits = self.seghead(f)\n        \n        f_up = F.interpolate(f, size=(IMG_SIZE, IMG_SIZE), mode='bilinear', align_corners=False)\n        \n        left_tokens = []\n        right_tokens = []\n        global_tokens = []\n        \n        for i in range(B):\n            fmap = f_up[i]\n            if mask is not None:\n                m = mask[i,0].detach().cpu().numpy()\n                ys, xs = np.where(m>0.5)\n                if len(xs) > 0:\n                    cx = int(xs.mean())\n                else:\n                    cx = IMG_SIZE//2\n            else:\n                cx = IMG_SIZE//2\n                \n            left_map = fmap[:, :, :cx] if cx > 1 else fmap[:,:, :1]\n            right_map = fmap[:, :, cx:] if cx < IMG_SIZE-1 else fmap[:,:, cx-1:cx]\n            \n            try:\n                lt = F.adaptive_avg_pool2d(left_map.unsqueeze(0), output_size=self.token_grid).squeeze(0)\n                rt = F.adaptive_avg_pool2d(right_map.unsqueeze(0), output_size=self.token_grid).squeeze(0)\n            except Exception:\n                lt = F.adaptive_avg_pool2d(fmap.unsqueeze(0), output_size=self.token_grid).squeeze(0)\n                rt = lt.clone()\n                \n            lt_tokens = lt.view(self.d_model, -1).permute(1,0)\n            rt_tokens = rt.view(self.d_model, -1).permute(1,0)\n            \n            gt = F.adaptive_avg_pool2d(fmap.unsqueeze(0), output_size=(max(1,self.token_grid[0]//2), max(1,self.token_grid[1]//2))).squeeze(0)\n            gt_tokens = gt.view(self.d_model, -1).permute(1,0)\n            \n            left_tokens.append(lt_tokens)\n            right_tokens.append(rt_tokens)\n            global_tokens.append(gt_tokens)\n\n        left_tokens = torch.stack([t for t in left_tokens], dim=0).to(x.device)\n        right_tokens = torch.stack([t for t in right_tokens], dim=0).to(x.device)\n        global_tokens = torch.stack([t for t in global_tokens], dim=0).to(x.device)\n\n        left_out = self.left_enc(left_tokens)\n        right_out = self.right_enc(right_tokens)\n        konk = torch.cat([global_tokens, left_out, right_out], dim=1)\n        global_out = self.global_enc(konk)\n\n        cls = self.cls_token.expand(B, -1, -1).to(x.device)\n        kv = torch.cat([left_out, right_out], dim=1)\n        cls_fused, attn_w = self.fusion(cls, kv)\n        logits = self.cls_head(cls_fused.squeeze(1))\n        \n        return logits, seg_logits, attn_w\n\n# -------------------------\n# Loss helpers\n# -------------------------\ndef dice_loss(pred, target, eps=1e-6):\n    pred = torch.sigmoid(pred)\n    inter = (pred * target).sum(dim=[1,2,3])\n    union = pred.sum(dim=[1,2,3]) + target.sum(dim=[1,2,3])\n    dice = (2*inter + eps) / (union + eps)\n    return 1.0 - dice.mean()\n\n# -------------------------\n# Instantiate model, optimizers\n# -------------------------\nmodel = HybridLungViT(num_classes=2, d_model=128, token_grid=(7,7)).to(DEVICE)\n\n# Use weighted loss for imbalanced data; label smoothing if available\ntry:\n    criterion_cls = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\nexcept TypeError:\n    criterion_cls = nn.CrossEntropyLoss(weight=class_weights)\n\nopt = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nsched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.5, patience=3, verbose=True)\n\n# Mixed precision scaler\nscaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n\nprint(\"Model with DEiT stem created!\")\nprint(\"Number of parameters:\", sum(p.numel() for p in model.parameters()))\n\n# -------------------------\n# TTA prediction helper (simple horiz flip average)\n# -------------------------\ndef tta_probs(model, xb, mask=None):\n    \"\"\"Return averaged positive-class probabilities (tensor on same device) for batch xb.\"\"\"\n    model.eval()\n    xb = xb.to(DEVICE)\n    probs_list = []\n    with torch.no_grad():\n        logits, _, _ = model(xb, mask)\n        p0 = torch.softmax(logits, dim=1)[:,1]\n        probs_list.append(p0)\n        # horizontal flip TTA\n        xb_flip = torch.flip(xb, dims=[3])\n        # flip mask too if provided\n        mask_flip = None\n        if mask is not None:\n            mask_flip = torch.flip(mask.to(DEVICE), dims=[3])\n        logits_f, _, _ = model(xb_flip, mask_flip)\n        p1 = torch.softmax(logits_f, dim=1)[:,1]\n        probs_list.append(p1)\n    # average\n    p_avg = torch.stack(probs_list, dim=0).mean(dim=0)\n    return p_avg\n\n# -------------------------\n# Enhanced evaluation function (uses TTA)\n# -------------------------\ndef evaluate(model, loader, detailed=False, use_tta=True):\n    model.eval()\n    correct = 0; total = 0\n    y_true = []; y_scores = []; y_pred = []\n    seg_losses = []\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Eval\"):\n            xb, yb, mask = batch\n            xb = xb.to(DEVICE); yb = yb.to(DEVICE); mask = mask.to(DEVICE)\n            \n            if use_tta:\n                probs = tta_probs(model, xb, mask)\n            else:\n                logits, seg_logits, _ = model(xb, mask)\n                probs = torch.softmax(logits, dim=1)[:,1]\n            \n            # For preds, threshold at 0.5 on averaged prob\n            preds = (probs > 0.5).long()\n            \n            # compute seg loss using single forward (no TTA) to avoid extra overhead\n            logits_single, seg_logits_single, _ = model(xb, mask)\n            if seg_logits_single.shape != mask.shape:\n                seg_logits_single = F.interpolate(seg_logits_single, size=(mask.shape[2], mask.shape[3]), mode='bilinear', align_corners=False)\n            seg_losses.append(dice_loss(seg_logits_single, mask).item())\n            \n            correct += (preds == yb).sum().item()\n            total += xb.size(0)\n            y_true.extend(yb.detach().cpu().numpy().tolist())\n            y_scores.extend(probs.detach().cpu().numpy().tolist())\n            y_pred.extend(preds.detach().cpu().numpy().tolist())\n    \n    acc = 100.0 * correct / total if total > 0 else 0.0\n    try:\n        auc = roc_auc_score(y_true, y_scores)\n    except Exception:\n        auc = float('nan')\n    \n    if detailed:\n        print(\"\\n\" + \"=\"*50)\n        print(\"DETAILED CLASSIFICATION REPORT:\")\n        print(\"=\"*50)\n        print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n        \n        cm = confusion_matrix(y_true, y_pred)\n        print(\"CONFUSION MATRIX:\")\n        print(cm)\n        if cm.size == (2,2):\n            print(f\"True Negatives: {cm[0,0]}, False Positives: {cm[0,1]}\")\n            print(f\"False Negatives: {cm[1,0]}, True Positives: {cm[1,1]}\")\n            specificity = cm[0,0] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0\n            sensitivity = cm[1,1] / (cm[1,0] + cm[1,1]) if (cm[1,0] + cm[1,1]) > 0 else 0\n            print(f\"Sensitivity/Recall: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n    \n    return acc, auc, np.mean(seg_losses) if seg_losses else float('nan'), y_true, y_pred, y_scores\n\n# -------------------------\n# Freeze / unfreeze helpers for stage-wise training\n# -------------------------\ndef set_stem_grad(enabled: bool):\n    for p in model.stem.deit.parameters():\n        p.requires_grad = enabled\n\n# freeze stem initially\nfreeze_epochs = 3\nset_stem_grad(False)\n\n# -------------------------\n# Training loop with early stopping\n# -------------------------\ntrain_losses = []; val_history = []\nbest_auc = -1.0\nbest_epoch = -1\nno_improve = 0\n\nprint(f\"Starting training with early stopping (patience={PATIENCE})...\")\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    t0 = time.time()\n    running_loss = 0.0\n    processed = 0\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n    \n    # unfreeze at specified epoch\n    if epoch == freeze_epochs + 1:\n        print(\"Unfreezing DEiT stem and lowering LR for finetuning\")\n        set_stem_grad(True)\n        for g in opt.param_groups:\n            g['lr'] = LR * 0.2  # lower LR when fine-tuning full model\n    \n    try:\n        for batch in pbar:\n            xb, yb, mask = batch\n            xb = xb.to(DEVICE); yb = yb.to(DEVICE); mask = mask.to(DEVICE)\n            \n            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n                logits, seg_logits, attn_w = model(xb, mask)\n                \n                if seg_logits.shape != mask.shape:\n                    seg_logits = F.interpolate(seg_logits, size=(mask.shape[2], mask.shape[3]), mode='bilinear', align_corners=False)\n                \n                ce = criterion_cls(logits, yb)\n                bce = F.binary_cross_entropy_with_logits(seg_logits, mask)\n                dloss = dice_loss(seg_logits, mask)\n                seg_loss = 0.5 * bce + 0.5 * dloss\n                attn_reg = torch.tensor(0.0, device=xb.device)\n                loss = ce + LAMBDA_SEG * seg_loss + LAMBDA_ATT * attn_reg\n            \n            opt.zero_grad()\n            scaler.scale(loss).backward()\n            \n            # Gradient clipping\n            scaler.unscale_(opt)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            scaler.step(opt)\n            scaler.update()\n            \n            running_loss += loss.item() * xb.size(0)\n            processed += xb.size(0)\n            avg_loss = running_loss / processed if processed > 0 else 0.0\n            pbar.set_postfix(loss=f\"{avg_loss:.4f}\", processed=processed)\n            \n    except KeyboardInterrupt:\n        print(\"\\nTraining interrupted by user (KeyboardInterrupt). Saving checkpoint...\")\n        ckpt_path = os.path.join(SAVE_DIR, f\"interrupted_epoch{epoch}_ckpt.pth\")\n        torch.save({\n            \"epoch\": epoch,\n            \"model_state\": model.state_dict(),\n            \"opt_state\": opt.state_dict(),\n            \"scaler_state\": scaler.state_dict(),\n            \"train_losses\": train_losses,\n            \"val_history\": val_history,\n            \"best_auc\": best_auc\n        }, ckpt_path)\n        print(\"Checkpoint saved to\", ckpt_path)\n        break\n\n    # Validation (use TTA for more stable val metrics)\n    val_acc, val_auc, val_seg_loss, _, _, _ = evaluate(model, val_loader, use_tta=True)\n    train_losses.append(running_loss / max(1, len(train_loader.dataset)))\n    val_history.append((val_acc, val_auc, val_seg_loss))\n    sched.step(val_auc)\n    \n    t1 = time.time()\n    print(f\"Epoch {epoch} finished in {t1-t0:.1f}s\")\n    print(f\"Val Acc: {val_acc:.2f}%, Val AUC: {val_auc:.4f}, Val Seg Loss: {val_seg_loss:.4f}\")\n    \n    # Early stopping check\n    if val_auc > best_auc + 0.001:\n        best_auc = val_auc\n        best_epoch = epoch\n        no_improve = 0\n        torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"best_model.pth\"))\n        print(f\"âœ… Saved best model (AUC improved to {best_auc:.4f})\")\n    else:\n        no_improve += 1\n        print(f\"â³ No improvement for {no_improve}/{PATIENCE} epochs (best AUC: {best_auc:.4f})\")\n    \n    if no_improve >= PATIENCE:\n        print(f\"ðŸ›‘ Early stopping triggered at epoch {epoch}!\")\n        break\n\nprint(f\"\\nTraining completed. Best val AUC: {best_auc:.4f} at epoch {best_epoch}\")\n\n# -------------------------\n# Final evaluation on test set\n# -------------------------\nif os.path.exists(os.path.join(SAVE_DIR, \"best_model.pth\")):\n    print(\"\\nLoading best model for final test evaluation...\")\n    model.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"best_model.pth\"), map_location=DEVICE))\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"FINAL TEST SET EVALUATION (with TTA)\")\n    print(\"=\"*60)\n    \n    test_acc, test_auc, test_seg_loss, test_true, test_pred, test_scores = evaluate(\n        model, test_loader, detailed=True, use_tta=True\n    )\n    \n    print(f\"\\nðŸ“Š TEST RESULTS:\")\n    print(f\"Test Acc: {test_acc:.2f}%\")\n    print(f\"Test AUC: {test_auc:.4f}\")\n    print(f\"Test Seg Loss: {test_seg_loss:.4f}\")\n    \n    # Compare with validation performance\n    print(f\"\\nðŸ“ˆ PERFORMANCE COMPARISON:\")\n    print(f\"Best Val AUC: {best_auc:.4f}\")\n    print(f\"Test AUC:     {test_auc:.4f}\")\n    print(f\"Gap:          {best_auc - test_auc:.4f}\")\n    \nprint(\"\\nDone. Model & artifacts saved under:\", SAVE_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:53:09.642245Z","iopub.execute_input":"2025-12-01T10:53:09.642829Z","iopub.status.idle":"2025-12-01T11:37:49.725968Z","shell.execute_reply.started":"2025-12-01T10:53:09.642797Z","shell.execute_reply":"2025-12-01T11:37:49.725046Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nDataset found: /kaggle/input/xraydata/chest_xray\nPreparing datasets...\nOriginal train size: 5216\nTrain indices: 4433, Val indices: 783\nSizes: train 4433 val 783 test 624\nClass counts: [1140 3293], Class weights: [1.4856756  0.51432437]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/tmp/ipykernel_47/1993662842.py:406: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n","output_type":"stream"},{"name":"stdout","text":"Model with DEiT stem created!\nNumber of parameters: 86868483\nStarting training with early stopping (patience=5)...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:02<00:00,  1.52it/s, loss=0.3041, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:29<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 finished in 212.0s\nVal Acc: 89.53%, Val AUC: 0.9843, Val Seg Loss: 0.9978\nâœ… Saved best model (AUC improved to 0.9843)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:01<00:00,  1.53it/s, loss=0.2432, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:29<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 finished in 210.6s\nVal Acc: 84.93%, Val AUC: 0.9906, Val Seg Loss: 0.9978\nâœ… Saved best model (AUC improved to 0.9906)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:00<00:00,  1.54it/s, loss=0.2384, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:29<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 finished in 210.3s\nVal Acc: 91.83%, Val AUC: 0.9939, Val Seg Loss: 0.9978\nâœ… Saved best model (AUC improved to 0.9939)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20:   0%|          | 0/277 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Unfreezing DEiT stem and lowering LR for finetuning\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:15<00:00,  1.42it/s, loss=0.2480, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 finished in 225.9s\nVal Acc: 93.49%, Val AUC: 0.9968, Val Seg Loss: 0.9978\nâœ… Saved best model (AUC improved to 0.9968)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:14<00:00,  1.43it/s, loss=0.2290, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 finished in 225.0s\nVal Acc: 93.36%, Val AUC: 0.9966, Val Seg Loss: 0.9978\nâ³ No improvement for 1/5 epochs (best AUC: 0.9968)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:15<00:00,  1.42it/s, loss=0.2198, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 finished in 225.8s\nVal Acc: 95.66%, Val AUC: 0.9975, Val Seg Loss: 0.9978\nâ³ No improvement for 2/5 epochs (best AUC: 0.9968)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:13<00:00,  1.43it/s, loss=0.2090, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 finished in 223.9s\nVal Acc: 95.66%, Val AUC: 0.9985, Val Seg Loss: 0.9978\nâœ… Saved best model (AUC improved to 0.9985)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:10<00:00,  1.46it/s, loss=0.2198, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 finished in 220.1s\nVal Acc: 96.04%, Val AUC: 0.9987, Val Seg Loss: 0.9978\nâ³ No improvement for 1/5 epochs (best AUC: 0.9985)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:10<00:00,  1.45it/s, loss=0.2012, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 finished in 220.9s\nVal Acc: 89.40%, Val AUC: 0.9982, Val Seg Loss: 0.9978\nâ³ No improvement for 2/5 epochs (best AUC: 0.9985)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:09<00:00,  1.46it/s, loss=0.2058, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 finished in 219.3s\nVal Acc: 94.76%, Val AUC: 0.9977, Val Seg Loss: 0.9978\nâ³ No improvement for 3/5 epochs (best AUC: 0.9985)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:13<00:00,  1.43it/s, loss=0.1938, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:32<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 finished in 226.3s\nVal Acc: 97.32%, Val AUC: 0.9986, Val Seg Loss: 0.9978\nâ³ No improvement for 4/5 epochs (best AUC: 0.9985)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20:   0%|          | 0/277 [00:00<?, ?it/s]/tmp/ipykernel_47/1993662842.py:535: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\nEpoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [03:17<00:00,  1.40it/s, loss=0.2088, processed=4432]\nEval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:30<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 finished in 227.9s\nVal Acc: 97.83%, Val AUC: 0.9990, Val Seg Loss: 0.9978\nâ³ No improvement for 5/5 epochs (best AUC: 0.9985)\nðŸ›‘ Early stopping triggered at epoch 12!\n\nTraining completed. Best val AUC: 0.9985 at epoch 7\n\nLoading best model for final test evaluation...\n\n============================================================\nFINAL TEST SET EVALUATION (with TTA)\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:27<00:00,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nDETAILED CLASSIFICATION REPORT:\n==================================================\n              precision    recall  f1-score   support\n\n      NORMAL       0.96      0.89      0.93       234\n   PNEUMONIA       0.94      0.98      0.96       390\n\n    accuracy                           0.95       624\n   macro avg       0.95      0.94      0.94       624\nweighted avg       0.95      0.95      0.95       624\n\nCONFUSION MATRIX:\n[[209  25]\n [  8 382]]\n\nðŸ“Š TEST RESULTS:\nTest Acc: 94.71%\nTest AUC: 0.9855\nTest Seg Loss: 0.6404\n\nðŸ“ˆ PERFORMANCE COMPARISON:\nBest Val AUC: 0.9985\nTest AUC:     0.9855\nGap:          0.0130\n\nDone. Model & artifacts saved under: ./ckpt_hybrid_deit_fixed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12}]}